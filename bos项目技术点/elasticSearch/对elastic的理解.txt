你们搜索用的是什么技术?

	solar 和

1.首先需要安装elasticsearch(流行原因是因为其强大的集群能力)(内置依赖jackson来转换)

产生这门技术的原因:为了解决大量数据的模糊查询 效率低又慢 的问题


解决方案:建立索引库 全文检索方式查询 

什么是全文检索:就是让搜索项  与 检索文本中的每个词进行比对
全文检索依赖于分词器,

比如一个地址搜索来举例子 :陕西省西安市 就像字典的目录一样()这种方式叫倒排索引

就词条跟索引来讲  我觉得词条就是更大化的划分 每一个词条都对应了许多索引  然后就可以针对这些索引更细化的查询

分词器对存于其中的文本数据分词  比如说:

陕西省 汉中市
陕西省 有这么多市 这么多区  每一个区都有对应的id

陕西省(一个词条):对应的值 就是我们每个区以逗号相隔的字符串   

如果你打一个陕西省 就会区这个遍历这个词条对应的所有的id  然后将遍历获取的一个数据集合 给你反回去
取交集

西安市

但有时候你也可能会遇到这种情况:就是说你打一个陕西 或者你打一个陕西省汉中市   但是所英库中存的数据是 陕西省

去拿词条跟你的搜索项进行比对 哎 发现这哥们这输的啥啊 这没一个词条能比对的上  呀 操 这咋整?!

因为elastic 这哥们它起初  也只有一个技能 就是词条等值查询  没有别的技能  

于是  我们借助 一个api帮助elastic  进行查询  这个Api就很强大了  它其中包含了种种搜索辅助技能

比如 模糊查询   比如说一个地址 我想搜搜陕西省 底下有多少数据   省 不想打了  我就打个陕西 

这里咱们分两种情况去对它进行介绍

1.我不是使用API  我直接查  哎呦 我擦 这玩意 搜索 卧槽这啥玩意 行不行 呀 啥都没有 这么垃圾 

就会对其进行分词 

分词（好的）： ElasticSearch、是、一个、基于、Lucene、搜索、服务、服务器
默认分词（差）： ElasticSearch、 是、一、个、基、于、搜、索



所以就不能使用它默认的分词器  我们必须采用一种自主分词的方式来 对数据完美的分词

于是 ik分词器就出现了,专门用于解决这种默认分词器分词能力不足的情况,并且它采用了特有的算法,
提高了处理能力,并号称美妙50万的分词处理()

存储文档时 只需要指定它的analyzer属性: ik即可

如何让查询结果 高亮显示?

	其实底层就是为需要高亮显示查询关键结果使用了  一个<em/>的css样式 指定字体颜色和样式

用高亮后的内容  替换原有内容


什么是spring data elesticSearch?

	就是基于spring datat API 简化elasticSearch 操作  将原始操作elasticSearch的客户端进行封装


